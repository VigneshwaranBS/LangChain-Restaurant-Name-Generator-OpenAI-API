{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from secret_key import openai_key\n",
    "os.environ['OPENAI_API_KEY'] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tavola Italiana\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.3)\n",
    "name = llm(\"I want to open a restuarnt for itailan food . suggest a fancy name for this\")    \n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restuarnt for Italian food . suggest a fancy name for this'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_temp_name= PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template= \"I want to open a restuarnt for {cuisine} food . suggest a fancy name for this\"\n",
    ")\n",
    "\n",
    "prompt_temp_name.format(cuisine=\"Italian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe American Bistro'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain=LLMChain(llm=llm , prompt=prompt_temp_name)\n",
    "chain.run(\"American\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.3)\n",
    "prompt_temp_name= PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template= \"I want to open a restuarnt for {cuisine} food . suggest a fancy name for this\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm , prompt=prompt_temp_name)\n",
    "\n",
    "# second chain\n",
    "\n",
    "prompt_temp_item= PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template= \"Suggest some menu item for {restaurant_name}. Return it as comma seprated list\"\n",
    ")\n",
    "\n",
    "food_item_chain = LLMChain(llm=llm , prompt=prompt_temp_item)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hamburgers, French Fries, Hot Dogs, Grilled Cheese Sandwiches, Chicken Tenders, Buffalo Wings, Onion Rings, Milkshakes, Apple Pie, Cheeseburgers.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[name_chain ,food_item_chain])\n",
    "\n",
    "res =chain.run(\"American\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  multiple output\n",
    "\n",
    "llm = OpenAI(temperature=0.6)\n",
    "prompt_temp_name= PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template= \"I want to open a restuarnt for {cuisine} food . suggest a fancy name for this\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm , prompt=prompt_temp_name , output_key=\"restaurant_name\")\n",
    "\n",
    "# second chain\n",
    "\n",
    "prompt_temp_item= PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template= \"Suggest some menu item for {restaurant_name}. Return it as comma seprated list\"\n",
    ")\n",
    "\n",
    "food_item_chain = LLMChain(llm=llm , prompt=prompt_temp_item ,output_key=\"Menu_items\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'american',\n",
       " 'restaurant_name': '\\n\\nAmerican Elegance',\n",
       " 'Menu_items': '\\n\\nGrilled Salmon, Roast Beef, Baked Potato, Asparagus Spears, Sautéed Mushrooms, Creamy Caesar Salad, Chicken Parmigiana, Apple Pie, Vanilla Ice Cream'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(\n",
    "    chains=[name_chain , food_item_chain],\n",
    "    input_variables=['cuisine'],\n",
    "    output_variables=['restaurant_name' , 'Menu_items']\n",
    ")\n",
    "\n",
    "chain({'cuisine':'american'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Elon Musk was born and use that to calculate his age in 2023\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk ( EE-lon; born June 28, 1971) is a business magnate and investor. He is the founder, CEO and chief engineer of SpaceX; angel investor, CEO and product architect of Tesla, Inc.; founder, owner, CTO and chairman of X Corp.; founder of the Boring Company; co-founder of Neuralink and OpenAI; and president of the philanthropic Musk Foundation. Musk is the wealthiest person in the world, with an estimated net worth as of July 2, 2023, of around US$234 billion according to the Bloomberg Billionaires Index and $238 billion according to Forbes's Real Time Billionaires list, primarily from his ownership stakes in Tesla and SpaceX.Musk was born in Pretoria, South Africa, and briefly attended the University of Pretoria before moving to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University and transferred to the University of Pennsylvania, where he received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University. After two days, he dropped out and, with his brother Kimbal, co-founded the online city guide software company Zip2. Zip2 was acquired by Compaq for $307 million in 1999, and with $12 million of the money he made, that same year Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal. \n",
      "In 2002, eBay acquired PayPal for $1.5 billion, and that same year, with $100 million of the money he made, Musk founded SpaceX, a spaceflight services company. In 2004, he was an early investor in the electric vehicle manufacturer Tesla Motors, Inc. (now Tesla, Inc.). He became its chairman and product architect, assuming the position of CEO in 2008. In 2006, he helped create SolarCity, a solar energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, Musk proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year, he co-founded Neuralink—a neurotechnology company developing brain–computer interfaces—and the Boring Company, a tunnel construction company. In 2022, his acquisition of Twitter for $44 billion was completed. \n",
      "Musk has expressed views that have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including that of spreading COVID-19 misinformation. In 2018, the U.S. Securities and Exchange Commission (SEC) sued Musk for falsely tweeting that he had secured funding for a private takeover of Tesla. To settle the case, Musk stepped down as chairman of Tesla and paid a $20 million fine.\n",
      "\n",
      "Page: Acquisition of Twitter by Elon Musk\n",
      "Summary: Business magnate Elon Musk initiated an acquisition of American social media company Twitter, Inc. on April 14, 2022, and concluded it on October 27, 2022. Musk had begun buying shares of the company in January 2022, becoming its largest shareholder by April with a 9.1 percent ownership stake. Twitter invited Musk to join its board of directors, an offer he initially accepted before declining. On April 14, Musk made an unsolicited offer to purchase the company, to which Twitter's board initially responded with a \"poison pill\" strategy to resist a hostile takeover, before unanimously accepting Musk's buyout offer of $44 billion on April 25. Musk stated that he planned to introduce new features to the platform, make its algorithms open-source, combat spambot accounts, and promote free speech.\n",
      "In July, Musk announced his intention to terminate the agreement, asserting that Twitter had breached their agreement by refusing to crack down on spambot accounts. The company filed a lawsuit against Musk in the Delaware Court of Chancery shortly thereafter, with a trial scheduled for the week of October 17. Weeks before the trial was set to begin, Musk reversed course, announcing that he would move forward with the acquisition. The deal was c\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the information to calculate Elon Musk's age in 2023\n",
      "Action: Calculator\n",
      "Action Input: 71 + 2023 - 2021\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 73\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Elon Musk will be 73 years old in 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Elon Musk will be 73 years old in 2023.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType , initialize_agent , load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "tools = load_tools(['wikipedia','llm-math'],llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose =True\n",
    ")\n",
    "\n",
    "agent.run(\"When was elon musk born ? what is his age now in 2023\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SERPAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  secret_key import serpapi_key\n",
    " \n",
    "os.environ['SERPAPI_API_KEY'] = serpapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m This is a question that requires research \n",
      "Action: Search \n",
      "Action Input: India GDP 2022 \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mReal GDP or GDP at Constant (2011-12) Prices in the year 2022-23 is estimated to attain a level of ₹160.06 lakh crore, as against the First Revised Estimates of GDP for the year 2021-22 of ₹149.26 lakh crore. The growth in real GDP during 2022-23 is estimated at 7.2 per cent as compared to 9.1 per cent in 2021-22. 4.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This looks like the answer I need \n",
      "Final Answer: Real GDP or GDP at Constant (2011-12) Prices in the year 2022-23 is estimated to attain a level of ₹160.06 lakh crore.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Real GDP or GDP at Constant (2011-12) Prices in the year 2022-23 is estimated to attain a level of ₹160.06 lakh crore.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "tools = load_tools([\"serpapi\" , \"llm-math\"],llm=llm)\n",
    "\n",
    "agent =initialize_agent(tools,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "\n",
    "agent.run(\"What was the GDP of INDIA in 2022? \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__class_vars__',\n",
       " '__config__',\n",
       " '__custom_root_type__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__exclude_fields__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_validators__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__include_fields__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__json_encoder__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__post_root_validators__',\n",
       " '__pre_root_validators__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__schema_cache__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__try_update_forward_refs__',\n",
       " '__validators__',\n",
       " '_abc_impl',\n",
       " '_acall',\n",
       " '_calculate_keys',\n",
       " '_call',\n",
       " '_chain_type',\n",
       " '_copy_and_set_values',\n",
       " '_decompose_class',\n",
       " '_enforce_dict_if_root',\n",
       " '_get_value',\n",
       " '_init_private_attributes',\n",
       " '_iter',\n",
       " '_lc_kwargs',\n",
       " '_run_output_key',\n",
       " '_validate_inputs',\n",
       " '_validate_outputs',\n",
       " 'acall',\n",
       " 'apply',\n",
       " 'arun',\n",
       " 'callback_manager',\n",
       " 'callbacks',\n",
       " 'chains',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'input_keys',\n",
       " 'input_variables',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_namespace',\n",
       " 'lc_secrets',\n",
       " 'lc_serializable',\n",
       " 'memory',\n",
       " 'output_keys',\n",
       " 'output_variables',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'prep_inputs',\n",
       " 'prep_outputs',\n",
       " 'raise_deprecation',\n",
       " 'return_all',\n",
       " 'run',\n",
       " 'save',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'set_verbose',\n",
       " 'tags',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'validate_chains',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " restaurant\n",
      "\n",
      "La Dolce Vita Italiana\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "Memory=ConversationBufferMemory()\n",
    "chain = LLMChain(llm=llm , prompt=prompt_temp_name)\n",
    "name = chain.run('Itaialn')\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Spice N' Soul\"\n"
     ]
    }
   ],
   "source": [
    "name = chain.run('south indian')\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo =ConversationChain(llm=OpenAI(temperature=0.6))\n",
    "\n",
    "convo.prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, I don't know the answer to that.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who won IPL 2023 ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' You already asked me that question. The answer is still 10.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run('5+5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Who won IPL 2023 ?', additional_kwargs={}, example=False), AIMessage(content=\" I'm sorry, I don't know the answer to that.\", additional_kwargs={}, example=False), HumanMessage(content='5+5', additional_kwargs={}, example=False), AIMessage(content=' The answer is 10.', additional_kwargs={}, example=False), HumanMessage(content='5+5', additional_kwargs={}, example=False), AIMessage(content=' You already asked me that question. The answer is still 10.', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Who won IPL 2023 ?\\nAI:  I'm sorry, I don't know the answer to that.\\nHuman: 5+5\\nAI:  The answer is 10.\\nHuman: 5+5\\nAI:  You already asked me that question. The answer is still 10.\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' India won the ICC World Cup in 2011. It was the tenth edition of the tournament and was held in India, Sri Lanka, and Bangladesh.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm = OpenAI(temperature=0.6),\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "convo.run(\"When was india won ICC world cup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
